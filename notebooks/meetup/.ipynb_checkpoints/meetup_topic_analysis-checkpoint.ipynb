{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import datetime\n",
    "import ratelim\n",
    "import os\n",
    "\n",
    "#Import gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load tagger once instead of unpickling from disk\n",
    "# http://stackoverflow.com/questions/11610076/slow-performance-of-pos-tagging-can-i-do-some-kind-of-pre-warming\n",
    "tagger = PerceptronTagger()\n",
    "\n",
    "# Same with tokenizer\n",
    "# http://billchambers.me/tutorials/2015/01/14/python-nlp-cheatsheet-nltk-scikit-learn.html\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "tokenizor = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# taken from http://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas\n",
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "\n",
    "    return conn[db]\n",
    "\n",
    "\n",
    "def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)\n",
    "\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = db[collection].find(query)\n",
    "\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(list(cursor))\n",
    "\n",
    "    # Delete the _id\n",
    "    if no_id:\n",
    "        del df['_id']\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def pre_process_text(document):\n",
    "    '''\n",
    "    input = document, a string\n",
    "    output = A list of tokens for analysis in gensim\n",
    "    '''\n",
    "    \n",
    "    #To lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    #Remove html\n",
    "    document = strip_fluff(document)\n",
    "    \n",
    "    #Tokenize and lemmatize\n",
    "    sents = sent_detector.tokenize(document)\n",
    "    tokens = []\n",
    "    for sent in sents:\n",
    "        tokens += tokenizor.tokenize(sent)\n",
    "    tokens = [x for x in tokens if x not in(string.punctuation)]\n",
    "    tokens_lemmatized = [lmtzr.lemmatize(token) for token in tokens]\n",
    "\n",
    "    #Get position\n",
    "    tagset = None\n",
    "    tokens_lab = tagger.tag(tokens_lemmatized)\n",
    "    \n",
    "    #Focus on nouns and remove stopwords\n",
    "    tokens_selected = [tok[0] for tok in tokens_lab if tok[0] not in words_to_remove and tok[1]==\"NN\"]\n",
    "    \n",
    "    return tokens_selected\n",
    "\n",
    "def strip_fluff(doc):\n",
    "    s = strip_html(doc)\n",
    "    s = strip_url(s)\n",
    "    s = strip_newline(s)\n",
    "    s = strip_nbsp(s)\n",
    "    return s\n",
    "\n",
    "def strip_html(doc):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub(' ', doc)\n",
    "\n",
    "def strip_url(doc):\n",
    "    return re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', doc)\n",
    "\n",
    "def strip_newline(doc):\n",
    "    return doc.replace('\\n', ' ')\n",
    "\n",
    "def strip_nbsp(doc):\n",
    "    return doc.replace('&nbsp;', ' ')\n",
    "\n",
    "def strip_html_entity(doc):\n",
    "    return doc.replace('&amp;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_meetups = read_mongo('meetup', 'groups')\n",
    "tech_meetups = read_mongo('meetup_tech_groups', 'groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Groups First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_meetups = read_mongo('meetup', 'groups')\n",
    "\n",
    "# Extract group cities. We will remove them later from text descriptions\n",
    "group_cities = list(set(business_meetups.city.str.lower()))\n",
    "\n",
    "# Load stop words.\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Lets remove all english words\n",
    "english_words = words.words()\n",
    "\n",
    "# Day names\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "\n",
    "#Load lemmatizer to lemmatize words\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "#Create list of words to remove\n",
    "words_to_remove = set(stop_words+list(group_cities)+english_words+['meetup', 'meet-up']+days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A list of group descriptions\n",
    "group_descriptions = [strip_fluff(str(x)) for x in business_meetups.description]\n",
    "\n",
    "#Process all text\n",
    "group_description_corpus = [pre_process_text(doc) for doc in group_descriptions]\n",
    "\n",
    "#Create a dictionary of unique tokens\n",
    "dictionary = corpora.Dictionary(group_description_corpus)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in group_description_corpus]\n",
    "\n",
    "tf_idf = models.TfidfModel(corpus)\n",
    "tf_idf_corpus = tf_idf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*cambridgeshire + 0.013*face-to-face + 0.012*co-founder + 0.010*xx + 0.010*amp + 0.007*lavinia + 0.006*database + 0.006*we’ll + 0.006*responsivecoffee + 0.006*owner/manager'),\n",
       " (1,\n",
       "  '0.030*• + 0.022*forex + 0.017*don’t + 0.015*“ + 0.011*app + 0.010*coffee/glass + 0.010*amp + 0.008*organisation + 0.008*john + 0.007*asc'),\n",
       " (2,\n",
       "  '0.039*bitcoin + 0.021*pma + 0.014*blockchain + 0.013*part-time + 0.013*internet + 0.011*amp + 0.011*and/or + 0.011*wider + 0.010*· + 0.009*uk'),\n",
       " (3,\n",
       "  \"0.049*socialise + 0.014*email + 0.011*'nlp + 0.009*ltd + 0.007*hubspot + 0.006*co-worker + 0.006*bbc + 0.005*pricing + 0.005*organising + 0.005*mba\"),\n",
       " (4,\n",
       "  '0.228*networking + 0.033*planning + 0.022*you’ll + 0.018*ipse + 0.017*stimulating + 0.015*amp + 0.012*freelancer + 0.012*organisation + 0.010*jci + 0.009*ebay'),\n",
       " (5,\n",
       "  '0.014*play® + 0.009*vibe + 0.009*lego® + 0.007*bos + 0.006*facebook + 0.006*amp + 0.006*geekeasy + 0.006*centred + 0.006*salesforce.com + 0.006*multi-jurisdiction'),\n",
       " (6,\n",
       "  '0.025*– + 0.021*fx + 0.008*entrepreneurialism + 0.008*amp + 0.008*cafe + 0.007*india + 0.007*huntingdonshire + 0.007*tv + 0.006*organisation + 0.006*bradbury'),\n",
       " (7,\n",
       "  '0.170*startup + 0.023*hmo + 0.019*financing + 0.018*blogger + 0.015*amp + 0.014*uk + 0.011*londonentrepreneursnetwork.com + 0.010*linkedin + 0.007*commercialisation + 0.007*kickstartup'),\n",
       " (8,\n",
       "  '0.018*startup + 0.016*manufacturing + 0.016*solver’ + 0.009*workforce + 0.008*organisation + 0.008*• + 0.008*visualisation + 0.007*pj + 0.005*kauffman + 0.005*july'),\n",
       " (9,\n",
       "  '0.025*attendee + 0.025*hampshire + 0.018*amp + 0.014*b2b + 0.013*zealand + 0.012*expertise + 0.012*city’s + 0.011*bar/restaurant + 0.011*client/customer + 0.011*j.z'),\n",
       " (10,\n",
       "  '0.087*expertise + 0.019*freelance + 0.014*ecommerce + 0.010*bedfordshire + 0.010*start-ups + 0.009*networking + 0.009*bni + 0.007*organisation + 0.007*newbie + 0.006*know-how'),\n",
       " (11,\n",
       "  '0.095*freelancer + 0.059*organisation + 0.021*ceo + 0.019*healthcare + 0.018*website + 0.017*amp + 0.013*networking + 0.011*acordia + 0.009*freelancing + 0.008*marketplace'),\n",
       " (12,\n",
       "  '0.019*networking + 0.017*-learn + 0.017*-add + 0.014*it’s + 0.011*organiser + 0.009*tottenham + 0.008*women’s + 0.007*workspace + 0.007*mlm + 0.006*self-confidence'),\n",
       " (13,\n",
       "  '0.055*funding + 0.017*cashflow + 0.017*self-confidence + 0.011*organisation + 0.010*startup + 0.009*facebook + 0.007*kwaku + 0.007*demo + 0.006*podcast + 0.006*youtube'),\n",
       " (14,\n",
       "  '0.031*mentoring + 0.013*europe + 0.011*google + 0.011*automation + 0.010*amp + 0.010*buy-to-let + 0.009*edtech + 0.009*endeavour + 0.008*tailor-made + 0.008*online'),\n",
       " (15,\n",
       "  '0.069*amp + 0.053*uk + 0.031*etc + 0.017*cv + 0.015*jewellery + 0.012*buying + 0.012*lifestyle + 0.008*networking + 0.007*le + 0.007*programme'),\n",
       " (16,\n",
       "  \"0.041*mindset + 0.029*england + 0.013*info + 0.012*mini + 0.011*co + 0.009*iaf + 0.008*'foundation + 0.008*hilton + 0.007*playing + 0.007*situtation\"),\n",
       " (17,\n",
       "  '0.082*online + 0.044*programme + 0.036*pm + 0.027*branding + 0.015*consultancy + 0.015*blog + 0.011*website + 0.011*get-together + 0.011*uk + 0.010*amp'),\n",
       " (18,\n",
       "  '0.025*smartphone + 0.017*fulfilment + 0.015*robert + 0.015*kiyosaki + 0.012*amp + 0.012*berkshire + 0.010*multi + 0.008*consisting + 0.007*admin + 0.007*studio…and'),\n",
       " (19,\n",
       "  \"0.039*meet-up + 0.023*brainstorm + 0.021*startup + 0.018*'word + 0.013*startupblink + 0.012*amp + 0.011*meetups + 0.010*networking + 0.010*passionpreneur + 0.007*etc\"),\n",
       " (20,\n",
       "  '0.028*pr + 0.020*wifi + 0.018*fintech + 0.012*online + 0.011*etc + 0.009*fsb + 0.009*i’ll + 0.009*cooperation + 0.008*in-house + 0.007*rsvp'),\n",
       " (21,\n",
       "  '0.045*investing + 0.032*facebook + 0.017*hertfordshire + 0.013*start-up + 0.013*amp + 0.012*• + 0.011*website + 0.009*mom + 0.009*kendall + 0.008*organiser'),\n",
       " (22,\n",
       "  '0.032*hr + 0.012*apps + 0.009*africa + 0.008*worldwide + 0.007*networking + 0.006*improv + 0.006*metre + 0.006*amp + 0.006*derbyshire + 0.006*yazor'),\n",
       " (23,\n",
       "  '0.049*internet + 0.041*software + 0.040*gt + 0.035*br + 0.031*online + 0.029*sharing + 0.026*lt + 0.014*startup + 0.013*sme + 0.010*essex'),\n",
       " (24,\n",
       "  '0.043*centre + 0.017*amp + 0.015*funding + 0.015*google + 0.014*pas + 0.012*startup + 0.010*amazon + 0.009*bos + 0.008*/p + 0.007*attendee')]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = models.LdaModel(tf_idf_corpus, id2word=dictionary, num_topics=25, passes=10, iterations=50)\n",
    "lda_model.show_topics(num_topics=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract group cities. We will remove them later from text descriptions\n",
    "tech_group_cities = list(set(tech_meetups.city.str.lower()))\n",
    "\n",
    "tech_meetups = read_mongo('meetup_tech_groups', 'groups')\n",
    "\n",
    "# Extract group cities. We will remove them later from text descriptions\n",
    "tech_group_cities = list(set(tech_meetups.city.str.lower()))\n",
    "\n",
    "# A list of group descriptions\n",
    "tech_group_descriptions = [strip_fluff(str(x)) for x in tech_meetups.description]\n",
    "\n",
    "#Process all text\n",
    "tech_group_description_corpus = [pre_process_text(doc) for doc in tech_group_descriptions]\n",
    "\n",
    "#Create a dictionary of unique tokens\n",
    "tech_dictionary = corpora.Dictionary(tech_group_description_corpus)\n",
    "tech_corpus = [tech_dictionary.doc2bow(doc) for doc in tech_group_description_corpus]\n",
    "\n",
    "tech_tf_idf = models.TfidfModel(tech_corpus)\n",
    "tech_tf_idf_corpus = tf_idf[tech_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.064*blog + 0.040*blogger + 0.024*reporting + 0.016*django + 0.016*kid + 0.016*haskell + 0.012*github + 0.012*demo + 0.011*startup + 0.010*etc'),\n",
       " (1,\n",
       "  '0.358*software + 0.017*api + 0.016*laptop + 0.012*automation + 0.011*amp + 0.011*arduino + 0.011*lunchtime + 0.008*we’re + 0.008*consultancy + 0.007*virtualization'),\n",
       " (2,\n",
       "  '0.046*facebook + 0.037*website + 0.032*processing + 0.019*organiser + 0.015*elasticsearch + 0.015*we’re + 0.015*software + 0.012*logstash + 0.011*paas + 0.010*inc.'),\n",
       " (3,\n",
       "  '0.108*networking + 0.063*amp + 0.016*sharing + 0.015*jboss + 0.011*java + 0.011*software + 0.011*pentaho + 0.009*copywriter + 0.009*hr + 0.008*workload'),\n",
       " (4,\n",
       "  '0.039*scotland + 0.019*software + 0.019*healthcare + 0.017*c++ + 0.013*ethereum + 0.012*powershell + 0.010*magento + 0.010*java + 0.009*accu + 0.009*magento2'),\n",
       " (5,\n",
       "  '0.062*cm + 0.044*linux + 0.021*amazon + 0.015*hackspace + 0.015*html + 0.011*ibm + 0.011*sencha + 0.010*javascript + 0.008*mk + 0.007*sussex'),\n",
       " (6,\n",
       "  '0.018*frontend + 0.015*inc + 0.014*africa + 0.011*logo + 0.009*makerspace + 0.009*etc. + 0.009*bennett-lovesey + 0.009*demo + 0.009*processing + 0.008*funding'),\n",
       " (7,\n",
       "  '0.075*expertise + 0.021*milton + 0.013*email + 0.011*meet-up + 0.011*software + 0.010*attendee + 0.010*hackathon + 0.010*wider + 0.009*hiring + 0.008*networking'),\n",
       " (8,\n",
       "  '0.114*database + 0.047*cassandra + 0.017*hadoop + 0.016*couchbase + 0.014*second-generation + 0.014*bigtable + 0.013*amp + 0.013*it’s + 0.012*scalability + 0.010*bi'),\n",
       " (9,\n",
       "  '0.069*attendee + 0.049*salesforce + 0.033*hadoop + 0.021*nosql + 0.016*ireland + 0.010*import.io + 0.009*junky + 0.007*amazon + 0.007*website + 0.006*diamandis'),\n",
       " (10,\n",
       "  '0.284*startup + 0.051*meet-up + 0.029*bitcoin + 0.012*amp + 0.012*demo + 0.011*optimisation + 0.010*ecommerce + 0.008*modelling + 0.008*software + 0.008*internet'),\n",
       " (11,\n",
       "  '0.132*organisation + 0.125*javascript + 0.024*socialise + 0.023*academia + 0.016*real-world + 0.015*amp + 0.010*aws + 0.007*laptop + 0.007*and/or + 0.007*organiser'),\n",
       " (12,\n",
       "  '0.079*• + 0.048*etc + 0.016*facebook + 0.014*diy + 0.011*symfony + 0.010*amp + 0.009*arduino + 0.009*phd + 0.008*england + 0.008*skyscanner'),\n",
       " (13,\n",
       "  '0.035*newbie + 0.031*organisation + 0.025*kanban + 0.012*sitecore + 0.011*hampshire + 0.011*e-commerce + 0.009*challenging + 0.009*le + 0.008*erlang + 0.007*website'),\n",
       " (14,\n",
       "  '0.167*programming + 0.069*coding + 0.021*blog + 0.014*monitoring + 0.014*kdb+ + 0.013*chin-wag + 0.013*producttank + 0.012*dojo + 0.011*john + 0.009*clojure'),\n",
       " (15,\n",
       "  \"0.111*google + 0.060*vr + 0.047*automation + 0.031*demo + 0.019*gdg + 0.013*startup + 0.012*amp + 0.011*consultancy + 0.009*'how + 0.007*smarter\"),\n",
       " (16,\n",
       "  '0.189*apps + 0.073*techie + 0.024*amp + 0.020*app + 0.016*top-quality + 0.011*visualisation + 0.010*tv + 0.009*rsvp + 0.008*html5 + 0.007*hashtag'),\n",
       " (17,\n",
       "  '0.135*online + 0.016*amp + 0.009*heard + 0.009*trademark + 0.008*demo + 0.007*linux + 0.007*tripadvisor + 0.007*relavent + 0.007*/javascript + 0.007*cissp'),\n",
       " (18,\n",
       "  '0.042*html5 + 0.019*magento + 0.019*javascript + 0.012*relating + 0.010*what’s + 0.008*arduino + 0.007*p.s + 0.007*onshape + 0.007*devon + 0.007*after-school'),\n",
       " (19,\n",
       "  '0.082*visualisation + 0.031*qa + 0.027*vms + 0.026*runtime + 0.022*packaging + 0.018*bcs + 0.011*app + 0.011*programme + 0.010*wellbeing + 0.010*brainstorm'),\n",
       " (20,\n",
       "  '0.148*internet + 0.020*sdk + 0.016*sharepoint + 0.011*december + 0.009*toolkit + 0.007*automation + 0.007*amp + 0.007*asp.net + 0.006*buckworth + 0.006*businesspeople'),\n",
       " (21,\n",
       "  '0.060*computing + 0.025*angularjs + 0.011*software + 0.010*javascript + 0.009*manufacturing + 0.008*opentechschool + 0.007*r. + 0.007*softlayer + 0.006*ibeacon + 0.006*plm'),\n",
       " (22,\n",
       "  '0.138*wordpress + 0.040*apis + 0.018*makerspace + 0.013*fintech + 0.009*open-source + 0.008*facebook + 0.008*website + 0.007*bdd + 0.007*dba + 0.007*seafood'),\n",
       " (23,\n",
       "  '0.084*php + 0.030*geeky + 0.020*shoreditch + 0.016*le + 0.014*code-fu + 0.011*amp + 0.007*freelance + 0.007*pmp + 0.007*entrepreneurs… + 0.007*computing/nosql'),\n",
       " (24,\n",
       "  '0.018*microsoft + 0.015*youtube + 0.012*linkedin + 0.010*amp + 0.009*bdd + 0.008*etc + 0.008*know-how + 0.007*visualisation + 0.007*millton + 0.007*warwickshire'),\n",
       " (25,\n",
       "  '0.049*sql + 0.045*database + 0.037*mysql + 0.033*ux + 0.031*mongodb + 0.018*publishing + 0.013*organisation + 0.013*devops + 0.009*september + 0.008*marklogic'),\n",
       " (26,\n",
       "  '0.092*java + 0.024*– + 0.018*and/or + 0.015*smartphone + 0.014*ceo + 0.014*europe + 0.011*etc + 0.009*axure + 0.007*eco-system + 0.007*cybertech'),\n",
       " (27,\n",
       "  '0.070*gt + 0.024*br + 0.020*yorkshire + 0.018*lt + 0.018*devs + 0.017*facebook + 0.014*hang + 0.013*sharing + 0.012*meetups + 0.011*offline'),\n",
       " (28,\n",
       "  '0.093*iot + 0.042*app + 0.029*freelancer + 0.025*internet + 0.024*amp + 0.022*.net + 0.018*centre + 0.015*gmail.com + 0.014*seo + 0.011*get-together'),\n",
       " (29,\n",
       "  '0.126*uk + 0.057*software + 0.035*england + 0.020*aws + 0.018*wider + 0.018*openstack + 0.015*mailing + 0.011*massingham + 0.008*usergroup + 0.007*ml')]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_lda_model = models.LdaModel(tech_tf_idf_corpus, id2word=tech_dictionary, num_topics=30, passes=30, iterations=100)\n",
    "tech_lda_model.show_topics(num_topics=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
